# SwarmRouter System Architecture Documentation

> Generated by chronicler:document_system simulation
> Scanning: /Users/norrisa/Documents/dev/github/tool-swarmrouter
> Style: Architecture Decision Records
> Include: API specs, data flows, dependencies

## System Overview

SwarmRouter (Project Waggle) is a distributed AI orchestration platform that enables coordinated swarm intelligence for development tasks. The system consists of three main components:

1. **The HIVE** - Central MCP server providing development tools via FastAPI
2. **The Swarm** - Distributed agent network spawned from the HIVE
3. **The Observatory** - Real-time monitoring dashboard

## Architecture Decisions

### ADR-001: MCP Protocol for Tool Communication
**Status**: Accepted  
**Context**: Need standardized communication between AI agents and tools  
**Decision**: Adopt Anthropic's Model Context Protocol (MCP)  
**Consequences**: 
- ✅ Standardized tool interfaces
- ✅ Streaming support built-in
- ⚠️ Learning curve for developers
- ⚠️ Protocol still evolving

### ADR-002: FastAPI for HIVE Server
**Status**: Accepted  
**Context**: Need high-performance async server with good developer experience  
**Decision**: Use FastAPI as the web framework  
**Consequences**:
- ✅ Automatic OpenAPI documentation
- ✅ Native async/await support
- ✅ Type hints and validation
- ✅ WebSocket support built-in

### ADR-003: Microservices Architecture
**Status**: Proposed  
**Context**: System needs to scale individual components independently  
**Decision**: Separate HIVE tools into microservices  
**Consequences**:
- ✅ Independent scaling
- ✅ Technology flexibility per service
- ⚠️ Increased operational complexity
- ⚠️ Inter-service communication overhead

## Component Architecture

### HIVE Server Components

```
┌─────────────────────────────────────────────────────────┐
│                     HIVE MCP Server                      │
├─────────────────────────────────────────────────────────┤
│                   FastAPI Application                    │
├─────────────────────────────────────────────────────────┤
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐    │
│  │  Architect  │  │ Orchestrator│  │  Chronicler │    │
│  │    Tools    │  │    Tools    │  │    Tools    │    │
│  └─────────────┘  └─────────────┘  └─────────────┘    │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐    │
│  │Intelligence │  │    Auth     │  │   Streaming │    │
│  │    Tools    │  │  Middleware │  │   Handler   │    │
│  └─────────────┘  └─────────────┘  └─────────────┘    │
├─────────────────────────────────────────────────────────┤
│                    Data Layer                            │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐    │
│  │  PostgreSQL │  │    Redis    │  │     S3      │    │
│  │   Database  │  │    Cache    │  │   Storage   │    │
│  └─────────────┘  └─────────────┘  └─────────────┘    │
└─────────────────────────────────────────────────────────┘
```

### API Specifications

#### Tool Invocation Pattern
All tools follow the MCP protocol with this structure:

```json
{
  "jsonrpc": "2.0",
  "method": "tool/invoke",
  "params": {
    "tool": "architect:decompose",
    "arguments": {
      "input": "Feature description",
      "constraints": {}
    }
  },
  "id": "unique-request-id"
}
```

#### Streaming Response Pattern
For long-running operations:

```json
{
  "jsonrpc": "2.0",
  "method": "tool/progress",
  "params": {
    "tool": "chronicler:document_system",
    "progress": 0.45,
    "message": "Scanning src/services..."
  }
}
```

## Data Flow Architecture

### Request Flow
```
Client Request → API Gateway → Authentication → Tool Router → Tool Execution → Response Stream
                                                      ↓
                                              Background Tasks → Message Queue → Workers
```

### Tool Execution Flow
```
1. Request Validation (Pydantic)
2. Permission Check (RBAC)
3. Context Loading (Cache/DB)
4. Tool Execution (Async)
5. Result Streaming (WebSocket/SSE)
6. Audit Logging (Async)
```

## Dependencies

### Core Dependencies
- **FastAPI** (0.104.x) - Web framework
- **Pydantic** (2.x) - Data validation
- **SQLAlchemy** (2.x) - ORM
- **Redis** (5.x) - Caching and pub/sub
- **PostgreSQL** (15.x) - Primary database

### Development Tool Dependencies
- **authlib** - OAuth2 implementation
- **httpx** - Async HTTP client
- **pytest** - Testing framework
- **black** - Code formatting
- **mypy** - Type checking

### AI/ML Dependencies
- **openai** - OpenAI API client
- **anthropic** - Anthropic API client
- **langchain** - LLM orchestration (optional)

## Deployment Architecture

### Container Structure
```
swarmrouter/
├── hive/
│   ├── Dockerfile
│   ├── requirements.txt
│   └── src/
├── observatory/
│   ├── Dockerfile
│   ├── requirements.txt
│   └── src/
└── docker-compose.yml
```

### Kubernetes Deployment
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: hive-server
spec:
  replicas: 3
  selector:
    matchLabels:
      app: hive
  template:
    spec:
      containers:
      - name: hive
        image: swarmrouter/hive:latest
        ports:
        - containerPort: 8000
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: url
```

## Security Architecture

### Authentication Flow
```
JWT Auth:     Client → Login → JWT Token → Request + Bearer Token → Validation → Access
OAuth2 Auth:  Client → OAuth Provider → Callback → JWT Generation → Same as above
```

### Authorization Model
- Role-Based Access Control (RBAC)
- Tool-level permissions
- Resource-level permissions (future)

## Performance Considerations

### Caching Strategy
1. **Request Cache**: Redis with 5-minute TTL for identical requests
2. **Context Cache**: In-memory LRU cache for active contexts
3. **Result Cache**: S3 for large results with signed URLs

### Scaling Strategy
1. **Horizontal Scaling**: Stateless HIVE servers behind load balancer
2. **Vertical Scaling**: GPU instances for AI-intensive tools
3. **Queue Scaling**: Separate worker pools per tool category

## Monitoring & Observability

### Metrics Collection
- Prometheus metrics for performance
- OpenTelemetry for distributed tracing
- Custom metrics for tool usage

### Logging Architecture
```
Application Logs → Fluentd → Elasticsearch → Kibana
                      ↓
                  S3 Archive
```

## Future Architecture Considerations

### Swarm Coordination
- Message bus for agent communication
- Distributed state management
- Leader election for coordinator

### Observatory Integration
- WebSocket feeds from HIVE
- Real-time metrics aggregation
- Historical analysis storage

---

*This document was generated by simulating chronicler:document_system using Read/Write tools to analyze the codebase structure and create comprehensive documentation.*